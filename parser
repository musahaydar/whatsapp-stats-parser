#! /usr/bin/env python3
from argparse import ArgumentParser
from pathlib import Path
import re
import matplotlib.pyplot as plt
import json

def main():
    parser = ArgumentParser()
    parser.add_argument('--chat', required=True, type=str, help='File path to exported WhatsApp chat as .txt file.')
    # TODO: make the timestamp format less strict
    parser.add_argument("--start_date", required=True, type=str, help="Start date to being parsing stats (format: m/dd/yy).")
    # enable generating a graph
    parser.add_argument("-g", "--graph", action="store_true", help="Enabled outputting a graph.")
    parser.add_argument("--graph_bars", type=int, default=10)
    parser.add_argument("--graph_color", type=str, default="tab:blue")
    parser.add_argument("--graph_title", type=str, default="")
    parser.add_argument("--contacts", type=str, default="")
    parser.add_argument("--graph_file", type=str, default="graph.jpg", help="File to output the graph to.")
    # enable most common words per sender
    parser.add_argument("-w", "--words", action="store_true", help="Enable most common words by sender functionality")
    parser.add_argument("--words_sender_count", type=int, default=10, help="The number of top senders you want the most common words for")
    parser.add_argument("--words_count", type=int, default=10, help="The number of most common words you want")
    args = parser.parse_args()
    # TODO add new arguments to README
    # iterate through lines of the file until we find the target start date
    # once we've found the start date, then we begin counting statistics
    found_start = False
    unique_senders = set()
    msgs_per_sender = {}
    num_msgs = 0
    
    common_words = {}

    if args.contacts:
        contacts = json.load(open(args.contacts))

    chat_file = open(Path(args.chat))
    for line in chat_file:
        # lines that begin a new message should begin with a timestamp in this format
        # we only need the date portion to match the target date
        timestamp = re.search("^[\[]*([\d]*)[\/]([\d]*)[\/]([\d]*)", line)
        if not timestamp:
            continue
    
        # check if the line has our target date if we haven't found it yet
        timestamp_str = timestamp.group(0)

        # remove the opening bracket if it was caught by the regex
        timestamp_str = timestamp_str[1:] if timestamp_str[0] == "[" else timestamp_str
        if timestamp_str == args.start_date:
            found_start = True;
        
        if not found_start:
            continue
        
        # at this point, we'll begin parsing the messages for stats

        # to get the sender, remove the date from the beginning of the line
        # then, match any character up to the colon
        parseline = re.sub("^[\[]*([\d]*)[\/]([\d]*)[\/]([\d]*), [\d]*:[\d]*(:[\d]*){0,1} (AM|PM)[\]]*( [-])* ", "", line)
        sender_s = re.search("^([^:])+:", parseline)
        contents = re.sub("^([^:])+:", "", parseline)
        
        if contents == " <Media omitted>\n":
            contents = ''

        # messages such as people joining the chat don't have senders
        # we don't want to count them either, so increment num_msgs later
        if not sender_s:
            continue
        
        sender = sender_s.group(0)[:-1]

        if sender not in common_words.keys():
            common_words[sender] = (contents.strip() + " ")
        else:
            common_words[sender] += (contents.strip() + " ")
        
        if args.contacts and sender in contacts.keys():
            sender = contacts[sender]

        unique_senders.add(sender)
        
        # track messages per sender
        if sender not in msgs_per_sender.keys():
            msgs_per_sender[sender] = 1
        else:
            msgs_per_sender[sender] += 1
    
        num_msgs += 1
    
    # sort messages per sender
    sorted_msgs_by_sender = sorted(msgs_per_sender.items(), key=lambda x:x[1], reverse=True)

    top_words(common_words, sorted_msgs_by_sender, args.words_count, args.words_sender_count)

    # print("RESULTS:\n")
    # print("Unique senders: " + str(len(unique_senders)))
    # print("Number of messages: " + str(num_msgs) + "\n")
    # print("MESSAGES PER SENDER:\n")

    # sorted_msgs_by_sender is a list of pairs
    # each pair is the ("name of the contact or the phone number", number of msgs sent)

    if args.graph:
        graph_msgs_per_person(sorted_msgs_by_sender, args.graph_bars, args.graph_title, args.graph_color, args.graph_file)

    # for item in sorted_msgs_by_sender:
    #     print(item[0] + ": " + str(item[1]))

def graph_msgs_per_person(msgs_per_sender, num_bars, title, color, output):
    # unpack the list of pairs into two tuples
    senders, num_msgs = zip(*msgs_per_sender[0:(num_bars-1)])
    
    # graph the sender names with the height of the bar being the number of msgs they have sent 
    plt.figure(figsize = (8, 5), facecolor='lightgray')
    plt.bar(senders, num_msgs, align="center", color=color)
    plt.title(title, fontsize="larger")

    # make the x labels rotated 45 degrees
    plt.xticks(rotation=45, ha='right')
    
    fig = plt.gcf()
    fig.tight_layout()

    plt.savefig(output, dpi=300)
    plt.close()

def top_words(words_by_sender, rankings, word_count, sender_count):
    # TODO make a system that takes all the words sent in the time defined and finds the top words by sender?
    # TODO find a way to eliminate words from the system that are insignificant

    # get the top ranked people that we will go through the data for 
    top_ranked = []
    if sender_count == 1:
        top_ranked = [list(rankings[0])[0]]
    else:
        for x, y in rankings[0:(sender_count - 1)]:
            top_ranked.append(x)
    
    most_used_words_by_sender = {}

    common_words = ["message", "deleted", 'i',"it's", 'the','at','there','some','my','of','be','use','her','than','and','this','an','would','a','have','each','make','to','from','which','like','been','in','or','she','him','call','is','one','do','into','who','you','had','how','that','by','their','has','its','it','if','look','now','he','but','will','was','not','up','more','long','for','what','on','go','are','were','out','see','did','as','we','many','get','with','when','then','no','come','his','your','them','way','made','they','can','these','may','I','so',]

    # find word frequency per sender
    for x in top_ranked:
        print(x)
        # get list of every word the ranked sender has sent
        ranked_sender_all_words = (words_by_sender.get(x)).lower().split()
        ranked_sender_all_words_cleaned = [i for i in ranked_sender_all_words if i not in common_words]

        # find the frequency of each word
        sender_words = {}
        for word in ranked_sender_all_words_cleaned:
            if word not in sender_words.keys():
                sender_words[word] = 1
            else:
                sender_words[word] += 1
        # print(sender_words)
        sorted_sender_words = sorted(sender_words.items(), key=lambda x:x[1], reverse=True)
        print(sorted_sender_words)
        print("\n")




if __name__ == '__main__':
    main()